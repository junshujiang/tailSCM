{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from helper_util import *\n",
    "import seaborn as sns\n",
    "from helper_simulation import expand_data_df\n",
    "current_date = datetime.now().strftime(\"%Y%m%d\")    \n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "%matplotlib inline\n",
    "\n",
    "INTERVAL=600\n",
    "pc_alpha=0.005\n",
    "quantile=0.5\n",
    "\n",
    "\n",
    "max_id=get_max(\"exp_result\")\n",
    "exp_str=\"\"\n",
    "log_path=f\"exp_result/{str(max_id)}.{current_date}.applicationChinaDerivatives_I{INTERVAL}\"\n",
    "\n",
    "df_price_volume=pd.read_parquet(\"/home/jianj0c/project/STP/dataset/price_volume.parquet\")\n",
    "\n",
    "logger=get_logger(log_path)\n",
    "\n",
    "\n",
    "logger.info(f\"INTERVAL: {INTERVAL}\")\n",
    "logger.info(f\"pc_alpha: {pc_alpha}\")\n",
    "logger.info(f\"quantile: {quantile}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path=f\"/home/jianj0c/project/STP/dataset/price_volume{INTERVAL}.parquet\"\n",
    "if os.path.exists(data_path):\n",
    "    df_in_one=pd.read_parquet(data_path)\n",
    "else:\n",
    "\n",
    "\n",
    "    price_series=df_price_volume[[x for x in df_price_volume.columns if x.endswith(\".price\")]]\n",
    "    return_df=pd.concat([price_series.pct_change(periods=INTERVAL),df_price_volume[[\"info.segment_index\"]]],axis=1).iloc[::INTERVAL,].copy()\n",
    "    return_df.loc[~return_df[\"info.segment_index\"].diff().eq(0).fillna(False),[x for x in return_df.columns if not x.startswith(\"info.\")]] = 0\n",
    "    # remove the return that span two sections\n",
    "\n",
    "    volumes=df_price_volume[[x for x in df_price_volume.columns if x.endswith(\".volume\")]+[\"info.segment_index\",\"info.tradingday\"]].copy()\n",
    "    daily_volumes = volumes.groupby(\"info.tradingday\").apply(\n",
    "        lambda x: x[[c for c in x.columns if c.endswith(\".volume\")]].iloc[-1] \n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    incremental=volumes[[x for x in volumes.columns if x.endswith(\".volume\")]].diff(INTERVAL)\n",
    "    incremental[\"info.tradingday\"]=volumes[\"info.tradingday\"]\n",
    "\n",
    "    incremental=incremental.iloc[::INTERVAL,].copy()\n",
    "\n",
    "    results=(\n",
    "        incremental.groupby(\"info.tradingday\", group_keys=False)  \n",
    "        .apply(lambda x: x[[col for col in x if col.endswith(\".volume\")]] \n",
    "            .div(daily_volumes.loc[x.name], axis=1)\n",
    "            ) \n",
    "        .reset_index() \n",
    "    )\n",
    "\n",
    "\n",
    "    volume_percentage=results.fillna(0)\n",
    "    volume_percentage.set_index(\"raw.timeindex\",inplace=True,drop=True)\n",
    "    volume_percentage[\"info.segment_index\"]=return_df[\"info.segment_index\"]\n",
    "    volume_percentage.loc[~volume_percentage[\"info.segment_index\"].diff().eq(0).fillna(False),[x for x in volume_percentage.columns if not x.startswith(\"info.\")]] = 0\n",
    "\n",
    "    df_in_one=pd.concat([volume_percentage[[x for x in volume_percentage.columns if x.endswith(\".volume\")]],return_df[[x for x in return_df.columns if  x.endswith(\".price\")]]],axis=1)\n",
    "    df_in_one.to_parquet(data_path)\n",
    "\n",
    "\n",
    "df_in_one=df_in_one.reset_index(drop=True).copy()\n",
    "\n",
    "df_in_one.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools \n",
    "\n",
    "pc_alpha_list=[0.01]\n",
    "quantile_list=[0.5]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "all_assets=[]\n",
    "for category in categories:\n",
    "    all_assets.extend(categories[category])\n",
    "all_assets=sorted(all_assets)\n",
    "\n",
    "\n",
    "sub_df=df_in_one[[f\"{x}_0.price\" for x in all_assets]]\n",
    "\n",
    "\n",
    "data_df_bar=expand_data_df(sub_df)\n",
    "\n",
    "sub_df_vol=df_in_one[[f\"{x}_0.volume\" for x in all_assets]]\n",
    "\n",
    "data_df_bar_vol=pd.concat([data_df_bar,sub_df_vol],axis=1)\n",
    "\n",
    "\n",
    "for pc_alpha,quantile in [(0.01,0.5),(0.005,0.5),(0.01,1),(0.005,1)]:\n",
    "\n",
    "    resultsThisPaper,results_tail=method_this_paper(data_df_bar_vol,pc_alpha=pc_alpha,quantile=quantile,tau_max=1,both_tail_variable=sub_df.shape[1])\n",
    "\n",
    "    import pickle\n",
    "    pickle.dump(resultsThisPaper,open(os.path.join(log_path,f\"whole_market_resultsThisPaper{pc_alpha}_q{quantile}.pkl\"),\"wb\"))\n",
    "    pickle.dump(results_tail,open(os.path.join(log_path,f\"whole_market_results_detail{pc_alpha}_q{quantile}.pkl\"),\"wb\"))\n",
    "    pickle.dump(all_assets,open(os.path.join(log_path,f\"all_assets{pc_alpha}_q{quantile}.pkl\"),\"wb\"))\n",
    "    edge_number=((resultsThisPaper[:,:,0]!=\"\").sum()/2+(resultsThisPaper[:,:,1]!=\"\").sum())\n",
    "\n",
    "\n",
    "    possible_edge_number=((len(all_assets)*3)**2)\n",
    "    print(f\"edge number: {edge_number}, possible edge number: {possible_edge_number}, sparsity ratio: {edge_number/possible_edge_number:.2%}\")\n",
    "    logger.info(f\"edge number: {edge_number}, possible edge number: {possible_edge_number}, sparsity ratio: {edge_number/possible_edge_number:.2%}\")\n",
    "    var_names=np.array([f\"${i}^{{u}}$\" for i in all_assets]+[f\"${i}^{{l}}$\" for i in all_assets]+[f\"${i}.vol$\" for i in all_assets])\n",
    "\n",
    "\n",
    "    save_path=os.path.join(log_path,f\"all_assets_olut_timeseries_graph{pc_alpha}_q{quantile}.png\")\n",
    "\n",
    "    draw_graph_timeseries(vmin_edges=0,vmax_edges=1,show_colorbar=False,save_path=save_path,**sort_name_and_edge_price_volume(resultsThisPaper,var_names),figsize=(50,50))\n",
    "\n",
    "    save_path=os.path.join(log_path,f\"all_assets_olut_graph{pc_alpha}_q{quantile}.png\")\n",
    "    logger.info(f\"save path: {save_path}\")\n",
    "\n",
    "    figsize=(50,50)\n",
    "    draw_graph(arrow_linewidth=3,arrowhead_size=5,node_size=0.02,label_fontsize=15,figsize=figsize,**sort_name_and_edge_price_volume(resultsThisPaper,var_names),save_path=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
